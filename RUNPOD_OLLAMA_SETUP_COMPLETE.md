# ðŸš€ RunPod'da Ollama Kurulumu ve BaÅŸlatma (Tam Rehber)

## 1. Ollama'yÄ± Ä°ndirme ve Kurma

RunPod terminal'inde (web terminal veya SSH) ÅŸu komutlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Ollama'yÄ± indir ve kur
curl -fsSL https://ollama.com/install.sh | sh
```

Bu komut:
- Ollama'yÄ± otomatik olarak indirir
- Sisteminize kurar
- `ollama` komutunu PATH'e ekler

**Kurulum tamamlandÄ±ktan sonra**, Ollama'nÄ±n kurulduÄŸunu kontrol edin:

```bash
ollama --version
```

## 2. Model Ä°ndirme

```bash
# qwen2.5:32b modelini indir (yaklaÅŸÄ±k 19 GB, 5-15 dakika sÃ¼rebilir)
ollama pull qwen2.5:32b
```

**Not:** Model indirme sÄ±rasÄ±nda terminal'de ilerleme gÃ¶receksiniz. Ä°ndirme tamamlanana kadar bekleyin.

Model indirildikten sonra kontrol edin:

```bash
# YÃ¼klÃ¼ modelleri listele
ollama list
```

`qwen2.5:32b` modelini gÃ¶rmelisiniz.

## 3. Ollama'yÄ± BaÅŸlatma (Port 11434'te)

RunPod'da Ollama'yÄ± tÃ¼m aÄŸlardan eriÅŸilebilir yapmak iÃ§in:

```bash
# Ã–nce varsa eski Ollama process'lerini durdur
pkill ollama

# Ollama'nÄ±n tÃ¼m aÄŸlardan eriÅŸilebilir olmasÄ± iÃ§in environment variable set et
export OLLAMA_HOST=0.0.0.0:11434

# Ollama'yÄ± arka planda baÅŸlat
nohup ollama serve > /tmp/ollama.log 2>&1 &
```

**Alternatif (daha detaylÄ± log iÃ§in):**

```bash
pkill ollama
export OLLAMA_HOST=0.0.0.0:11434
ollama serve &
```

## 4. Ollama'nÄ±n Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Kontrol Etme

```bash
# Ollama process'inin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol et
ps aux | grep ollama

# Port 11434'Ã¼n dinlendiÄŸini kontrol et (0.0.0.0:11434 veya *:11434 olmalÄ±)
ss -tuln | grep 11434
# veya
netstat -tuln | grep 11434

# Ollama API'sini test et (pod iÃ§inden)
curl http://localhost:11434/api/tags
```

**Beklenen Ã§Ä±ktÄ±:**
- `ps aux | grep ollama`: `ollama serve` process'i gÃ¶rÃ¼nmeli
- `ss -tuln | grep 11434`: `tcp LISTEN 0 4096 *:11434` veya `tcp LISTEN 0 4096 0.0.0.0:11434` gÃ¶rÃ¼nmeli
- `curl http://localhost:11434/api/tags`: JSON formatÄ±nda model listesi dÃ¶nmeli

## 5. RunPod HTTP Service KontrolÃ¼

RunPod panelinde "Connect" sekmesine gidin ve kontrol edin:

- **HTTP services** bÃ¶lÃ¼mÃ¼nde "Port 11434 â†’ HTTP Service" gÃ¶rÃ¼nmeli
- Durum "Ready" (yeÅŸil) olmalÄ±

EÄŸer gÃ¶rÃ¼nmÃ¼yorsa:
1. RunPod panelinde "Details" sekmesine gidin
2. "Expose HTTP Ports" bÃ¶lÃ¼mÃ¼nde `11434` olduÄŸundan emin olun
3. Pod'u yeniden baÅŸlatÄ±n (Stop â†’ Start)

## 6. Proxy URL Testi

Browser'da ÅŸu URL'yi aÃ§Ä±n (pod ID'nizi kullanÄ±n):

```
https://[pod-id]-11434.proxy.runpod.net/api/tags
```

**Beklenen sonuÃ§:**
- JSON formatÄ±nda model listesi gÃ¶rmelisiniz
- EÄŸer 404 hatasÄ± alÄ±rsanÄ±z, RunPod HTTP service'i dÃ¼zgÃ¼n Ã§alÄ±ÅŸmÄ±yor olabilir

## 7. Pod Yeniden BaÅŸlatÄ±ldÄ±ÄŸÄ±nda

RunPod pod'u yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda, Ollama'yÄ± tekrar baÅŸlatmanÄ±z gerekir:

```bash
# Ollama'yÄ± baÅŸlat
export OLLAMA_HOST=0.0.0.0:11434
nohup ollama serve > /tmp/ollama.log 2>&1 &
```

**Otomatik baÅŸlatma iÃ§in:** Pod'un startup script'ine ekleyebilirsiniz (RunPod template'inde "Start Command" bÃ¶lÃ¼mÃ¼ne):

```bash
export OLLAMA_HOST=0.0.0.0:11434 && ollama serve
```

## Sorun Giderme

### Ollama baÅŸlamÄ±yor
- Disk alanÄ±nÄ± kontrol edin: `df -h`
- LoglarÄ± kontrol edin: `cat /tmp/ollama.log`
- Port'un kullanÄ±lmadÄ±ÄŸÄ±nÄ± kontrol edin: `lsof -i :11434`

### Model yÃ¼klenmiyor
- Ä°nternet baÄŸlantÄ±sÄ±nÄ± kontrol edin
- Disk alanÄ±nÄ± kontrol edin (en az 25 GB boÅŸ alan gerekir)
- Daha kÃ¼Ã§Ã¼k bir model deneyin: `ollama pull llama2:7b`

### Port 11434 dinlenmiyor
- `OLLAMA_HOST=0.0.0.0:11434` deÄŸiÅŸkeninin set edildiÄŸinden emin olun
- Ollama'yÄ± yeniden baÅŸlatÄ±n: `pkill ollama && export OLLAMA_HOST=0.0.0.0:11434 && ollama serve &`

### Proxy URL Ã§alÄ±ÅŸmÄ±yor
- RunPod panelinde HTTP service'in "Ready" durumunda olduÄŸunu kontrol edin
- Pod ID'sinin doÄŸru olduÄŸunu kontrol edin
- Pod'u yeniden baÅŸlatmayÄ± deneyin

## Ã–zet Komutlar (HÄ±zlÄ± BaÅŸlangÄ±Ã§)

```bash
# 1. Ollama'yÄ± kur
curl -fsSL https://ollama.com/install.sh | sh

# 2. Model'i indir
ollama pull qwen2.5:32b

# 3. Ollama'yÄ± baÅŸlat
pkill ollama
export OLLAMA_HOST=0.0.0.0:11434
nohup ollama serve > /tmp/ollama.log 2>&1 &

# 4. Kontrol et
ollama list
curl http://localhost:11434/api/tags
```

## Backend YapÄ±landÄ±rmasÄ±

Pod ID'nizi aldÄ±ktan sonra, `docker-compose.yml` dosyasÄ±nda ÅŸu ÅŸekilde gÃ¼ncelleyin:

```yaml
LANGCHAIN4J_OLLAMA_CHAT_MODEL_BASE_URL: https://[pod-id]-11434.proxy.runpod.net
LANGCHAIN4J_OLLAMA_CHAT_MODEL_MODEL_NAME: qwen2.5:32b
```

Sonra backend'i yeniden baÅŸlatÄ±n:

```bash
docker-compose restart backend
```

