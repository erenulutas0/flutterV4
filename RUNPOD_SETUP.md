# ğŸš€ RunPod GPU Kiralama - HÄ±zlÄ± BaÅŸlangÄ±Ã§

## Ã–nemli Bilgiler

### âœ… Fiyat Sabit
- **Saatlik fiyat sabittir** - Hangi modeli kullanÄ±rsanÄ±z kullanÄ±n fiyat deÄŸiÅŸmez
- RTX 5090'Ä± $0.69/saat kiralarsanÄ±z, istediÄŸiniz kadar aÄŸÄ±r model kullanabilirsiniz
- Sadece **VRAM limiti** Ã¶nemli (modelin sÄ±ÄŸmasÄ± gerekir)

### ğŸ“Š GPU ve Model UyumluluÄŸu

| GPU | VRAM | Ã–nerilen Modeller | Saatlik Fiyat |
|-----|------|-------------------|---------------|
| RTX 3070 Ti (sizin) | 8GB | llama2:7b, mistral:7b | - |
| RTX 3090 | 24GB | llama2:7b, 13b, qwen2.5:32b | $0.22 |
| RTX 4090 | 24GB | llama2:7b, 13b, qwen2.5:32b | $0.34 |
| RTX 5090 | 32GB | TÃ¼m modeller (70B hariÃ§) | $0.69 |

## Test Ä°Ã§in Ã–neri: RTX 3090 ($0.22/saat)

**Neden RTX 3090?**
- âœ… En uygun fiyat (test iÃ§in ideal)
- âœ… 24GB VRAM (Ã§oÄŸu modeli Ã§alÄ±ÅŸtÄ±rÄ±r)
- âœ… 3070 Ti'nizden Ã§ok daha hÄ±zlÄ±
- âœ… HÄ±z farkÄ±nÄ± net gÃ¶rebilirsiniz

## AdÄ±m AdÄ±m Kurulum

### 1. RunPod'a KayÄ±t
1. https://www.runpod.io/ adresine gidin
2. "Sign Up" ile kayÄ±t olun
3. Billing bilgilerinizi ekleyin (kredi kartÄ±)

### 2. Ollama Pod'u OluÅŸtur

1. **"Pods"** sekmesine gidin
2. **"Deploy"** butonuna tÄ±klayÄ±n
3. **"Community Cloud"** seÃ§in
4. Template: **"Ollama"** seÃ§in
5. GPU: **RTX 3090** seÃ§in ($0.22/hr)
6. **"Deploy"** butonuna tÄ±klayÄ±n

### 3. Pod BaÅŸlatÄ±ldÄ±ktan Sonra

Pod baÅŸladÄ±ktan sonra (1-2 dakika):

1. Pod'un yanÄ±ndaki **"Connect"** butonuna tÄ±klayÄ±n
2. **"HTTP Service"** sekmesine gidin
3. **Public Endpoint** URL'ini kopyalayÄ±n
   - Ã–rnek: `https://xxxxx-xxxxx-5000.proxy.runpod.net`

### 4. Model YÃ¼kleme

**Terminal'den (RunPod web UI):**

```bash
# Pod'a baÄŸlan (RunPod web UI'dan terminal aÃ§Ä±n)

# HÄ±zlÄ± test iÃ§in 7B model
ollama pull llama2:7b

# Daha iyi kalite iÃ§in 13B model
ollama pull llama2:13b

# En iyi kalite iÃ§in 32B model (24GB VRAM limitinde)
ollama pull qwen2.5:32b
```

**Not:** Model yÃ¼kleme ilk seferde 5-15 dakika sÃ¼rebilir (model boyutuna gÃ¶re).

### 5. Backend YapÄ±landÄ±rmasÄ±

`docker-compose.yml` dosyasÄ±nÄ± dÃ¼zenleyin:

```yaml
# Ollama (RunPod GPU servisi)
LANGCHAIN4J_OLLAMA_CHAT_MODEL_BASE_URL: https://xxxxx-xxxxx-5000.proxy.runpod.net
LANGCHAIN4J_OLLAMA_CHAT_MODEL_MODEL_NAME: llama2:13b  # veya qwen2.5:32b
LANGCHAIN4J_OLLAMA_CHAT_MODEL_TEMPERATURE: 0.2
LANGCHAIN4J_OLLAMA_CHAT_MODEL_TIMEOUT: 300s
LANGCHAIN4J_OLLAMA_CHAT_MODEL_TOP_P: 0.9
```

**Ã–nemli:** 
- URL'de `http://` yerine `https://` kullanÄ±n
- Port numarasÄ± genellikle `:5000` veya `:11434` olur (RunPod size sÃ¶yler)

### 6. Backend'i Yeniden BaÅŸlat

```bash
docker-compose restart backend
```

### 7. Test Edin

1. UygulamayÄ± aÃ§Ä±n: http://localhost:8080
2. Bir kelime iÃ§in cÃ¼mle Ã¼retin
3. SÃ¼reyi Ã¶lÃ§Ã¼n ve karÅŸÄ±laÅŸtÄ±rÄ±n:
   - **Ã–nce (3070 Ti):** ~10-30 saniye
   - **Sonra (RTX 3090):** ~1-3 saniye

## Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### RTX 3070 Ti (8GB VRAM) - Sizin GPU
- **llama2:7b:** ~10-20 saniye/cÃ¼mle
- **llama2:13b:** Ã‡alÄ±ÅŸmaz (VRAM yetersiz)
- **qwen2.5:32b:** Ã‡alÄ±ÅŸmaz (VRAM yetersiz)

### RTX 3090 (24GB VRAM) - RunPod
- **llama2:7b:** ~0.5-1 saniye/cÃ¼mle âš¡
- **llama2:13b:** ~1-2 saniye/cÃ¼mle âš¡
- **qwen2.5:32b:** ~2-4 saniye/cÃ¼mle âš¡

**HÄ±z artÄ±ÅŸÄ±: 10-20x daha hÄ±zlÄ±!**

## Maliyet Tahmini

### Test Senaryosu (1 saat):
- RTX 3090: **$0.22**
- FarklÄ± modelleri test edebilirsiniz
- Ä°stediÄŸiniz kadar model yÃ¼kleyebilirsiniz (fiyat deÄŸiÅŸmez)

### GÃ¼nlÃ¼k KullanÄ±m (8 saat/gÃ¼n):
- RTX 3090: **$1.76/gÃ¼n** (~$53/ay)
- RTX 4090: **$2.72/gÃ¼n** (~$82/ay)
- RTX 5090: **$5.52/gÃ¼n** (~$166/ay)

### 24/7 KullanÄ±m:
- RTX 3090: **~$158/ay**
- RTX 4090: **~$245/ay**
- RTX 5090: **~$497/ay**

## Ã–nemli Notlar

1. **Pod'u DurdurmayÄ± UnutmayÄ±n!**
   - KullanmadÄ±ÄŸÄ±nÄ±zda pod'u durdurun (fiyatlandÄ±rma durur)
   - RunPod'da "Stop" butonuna tÄ±klayÄ±n

2. **Network Volume KullanÄ±n (Opsiyonel)**
   - Model dosyalarÄ±nÄ± kalÄ±cÄ± hale getirmek iÃ§in
   - Pod yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda modeller kaybolmaz

3. **Idle Timeout**
   - BazÄ± pod'lar kullanÄ±lmadÄ±ÄŸÄ±nda otomatik kapanÄ±r
   - Ayarlardan kontrol edin

4. **CORS AyarlarÄ±**
   - RunPod endpoint'leri genellikle HTTPS kullanÄ±r
   - CORS ayarlarÄ± backend'de zaten yapÄ±lmÄ±ÅŸ olmalÄ±

## Sorun Giderme

### Pod'a BaÄŸlanamÄ±yorum
- Pod'un "Running" durumunda olduÄŸundan emin olun
- Public endpoint URL'ini kontrol edin
- Firewall ayarlarÄ±nÄ± kontrol edin

### Model YÃ¼klenmiyor
- Pod'un yeterli disk alanÄ±na sahip olduÄŸundan emin olun
- Daha kÃ¼Ã§Ã¼k bir model deneyin (7B â†’ 13B â†’ 32B)

### Backend BaÄŸlanamÄ±yor
- URL'nin doÄŸru olduÄŸundan emin olun (https://)
- Port numarasÄ±nÄ± kontrol edin
- Backend loglarÄ±nÄ± kontrol edin: `docker-compose logs backend`

## SonuÃ§

**Test iÃ§in RTX 3090 ($0.22/saat) ile baÅŸlayÄ±n:**
- âœ… Uygun fiyat
- âœ… 24GB VRAM (Ã§oÄŸu modeli Ã§alÄ±ÅŸtÄ±rÄ±r)
- âœ… 3070 Ti'nizden 10-20x daha hÄ±zlÄ±
- âœ… Fiyat sabit (hangi modeli kullanÄ±rsanÄ±z kullanÄ±n)

**Performans beklentisi:**
- 3070 Ti: 10-30 saniye/cÃ¼mle
- RTX 3090: 1-3 saniye/cÃ¼mle
- **10-20x hÄ±zlanma!** ğŸš€


